server:
  port: 8084
spring:
  profiles:
    active: dev #默认为开发环境
  main:
    allow-bean-definition-overriding: true
  application:
    name: sparkzxl-kafka-producer
  lifecycle:
    timeout-per-shutdown-phase: 30s
  kafka:
    bootstrap-servers: 192.168.3.69:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
    # Kafka Consumer 配置项
    consumer:
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring:
          json:
            trusted:
              packages: com.github.sparkzxl.kafka.producer.entity
    # Kafka Consumer Listener 监听器配置
    listener:
      missing-topics-fatal: false # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
logging:
  level:
    org:
      springframework:
        kafka: ERROR # spring-kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
      apache:
        kafka: ERROR # kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
knife4j:
  enable: true
  description: sparkzxl kafka在线文档
  base-package: com.github.sparkzxl.kafka.producer.controller
  group: kafka生产应用
  title: sparkzxl kafka在线文档
  terms-of-service-url: https://www.sparksys.top
  version: 1.0
  license: Powered By sparkzxl
  license-url: https://github.com/sparkzxl
  contact:
    name: zhouxinlei
    email: zhouxinlei298@163.com
    url: https://github.com/sparkzxl
